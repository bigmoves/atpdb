# atpdb MVP Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Build a vertical slice of an AT Protocol native database: firehose → storage → query → CLI output.

**Architecture:** Single-binary Rust application with fjall for embedded storage. Firehose client connects to relay, decodes CBOR/CAR commits, stores records keyed by AT-URI. Query engine supports exact lookups and user collection wildcards. CLI REPL for interaction.

**Tech Stack:** Rust, fjall, tungstenite, ciborium, serde_json, rustyline

---

## Task 1: Project Setup

**Files:**
- Create: `Cargo.toml`
- Create: `src/main.rs`

**Step 1: Initialize Cargo project**

Run:
```bash
cargo init
```

**Step 2: Add dependencies to Cargo.toml**

```toml
[package]
name = "atpdb"
version = "0.1.0"
edition = "2024"

[dependencies]
fjall = "2"
tungstenite = "0.24"
ciborium = "0.2"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
rustyline = "14"
thiserror = "2"
url = "2"
```

**Step 3: Create minimal main.rs with banner**

```rust
fn main() {
    println!(r#"
   ___  ______ ___  ___  ___
  / _ |/_  __// _ \/ _ \/ _ )
 / __ | / /  / ___/ // / _  |
/_/ |_|/_/  /_/  /____/____/
"#);
    println!("atp> (not yet implemented)");
}
```

**Step 4: Verify it compiles and runs**

Run: `cargo run`
Expected: Banner prints, then exits

**Step 5: Commit**

```bash
git init
git add Cargo.toml src/main.rs
git commit -m "feat: initial project setup with banner"
```

---

## Task 2: Native Types

**Files:**
- Create: `src/types.rs`
- Modify: `src/main.rs`

**Step 1: Write tests for Did**

Create `src/types.rs`:

```rust
use std::fmt;
use std::str::FromStr;
use thiserror::Error;

#[derive(Error, Debug)]
pub enum ParseError {
    #[error("invalid DID: {0}")]
    InvalidDid(String),
    #[error("invalid NSID: {0}")]
    InvalidNsid(String),
    #[error("invalid rkey: {0}")]
    InvalidRkey(String),
    #[error("invalid AT-URI: {0}")]
    InvalidAtUri(String),
}

#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct Did(String);

impl Did {
    pub fn as_str(&self) -> &str {
        &self.0
    }
}

impl FromStr for Did {
    type Err = ParseError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        if s.starts_with("did:plc:") || s.starts_with("did:web:") {
            Ok(Did(s.to_string()))
        } else {
            Err(ParseError::InvalidDid(s.to_string()))
        }
    }
}

impl fmt::Display for Did {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_did_parse_plc() {
        let did: Did = "did:plc:z72i7hdynmk6r22z27h6tvur".parse().unwrap();
        assert_eq!(did.as_str(), "did:plc:z72i7hdynmk6r22z27h6tvur");
    }

    #[test]
    fn test_did_parse_web() {
        let did: Did = "did:web:example.com".parse().unwrap();
        assert_eq!(did.as_str(), "did:web:example.com");
    }

    #[test]
    fn test_did_parse_invalid() {
        let result: Result<Did, _> = "not-a-did".parse();
        assert!(result.is_err());
    }
}
```

**Step 2: Run tests**

Run: `cargo test test_did`
Expected: 3 tests pass

**Step 3: Add Nsid type**

Add to `src/types.rs`:

```rust
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct Nsid(String);

impl Nsid {
    pub fn as_str(&self) -> &str {
        &self.0
    }
}

impl FromStr for Nsid {
    type Err = ParseError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        // Basic validation: at least one dot, no spaces
        if s.contains('.') && !s.contains(' ') && !s.is_empty() {
            Ok(Nsid(s.to_string()))
        } else {
            Err(ParseError::InvalidNsid(s.to_string()))
        }
    }
}

impl fmt::Display for Nsid {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}
```

Add tests:

```rust
    #[test]
    fn test_nsid_parse() {
        let nsid: Nsid = "app.bsky.feed.post".parse().unwrap();
        assert_eq!(nsid.as_str(), "app.bsky.feed.post");
    }

    #[test]
    fn test_nsid_parse_invalid() {
        let result: Result<Nsid, _> = "noDots".parse();
        assert!(result.is_err());
    }
```

**Step 4: Run tests**

Run: `cargo test test_nsid`
Expected: 2 tests pass

**Step 5: Add Rkey type**

Add to `src/types.rs`:

```rust
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct Rkey(String);

impl Rkey {
    pub fn as_str(&self) -> &str {
        &self.0
    }
}

impl FromStr for Rkey {
    type Err = ParseError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        if !s.is_empty() && !s.contains('/') {
            Ok(Rkey(s.to_string()))
        } else {
            Err(ParseError::InvalidRkey(s.to_string()))
        }
    }
}

impl fmt::Display for Rkey {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}
```

Add tests:

```rust
    #[test]
    fn test_rkey_parse() {
        let rkey: Rkey = "3k2a1b".parse().unwrap();
        assert_eq!(rkey.as_str(), "3k2a1b");
    }

    #[test]
    fn test_rkey_self() {
        let rkey: Rkey = "self".parse().unwrap();
        assert_eq!(rkey.as_str(), "self");
    }
```

**Step 6: Run tests**

Run: `cargo test test_rkey`
Expected: 2 tests pass

**Step 7: Add AtUri type**

Add to `src/types.rs`:

```rust
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct AtUri {
    pub did: Did,
    pub collection: Nsid,
    pub rkey: Rkey,
}

impl AtUri {
    pub fn new(did: Did, collection: Nsid, rkey: Rkey) -> Self {
        Self { did, collection, rkey }
    }

    pub fn to_storage_key(&self) -> Vec<u8> {
        self.to_string().into_bytes()
    }
}

impl FromStr for AtUri {
    type Err = ParseError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        let s = s.strip_prefix("at://")
            .ok_or_else(|| ParseError::InvalidAtUri(s.to_string()))?;

        let parts: Vec<&str> = s.splitn(3, '/').collect();
        if parts.len() != 3 {
            return Err(ParseError::InvalidAtUri(s.to_string()));
        }

        let did: Did = parts[0].parse()?;
        let collection: Nsid = parts[1].parse()?;
        let rkey: Rkey = parts[2].parse()?;

        Ok(AtUri { did, collection, rkey })
    }
}

impl fmt::Display for AtUri {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "at://{}/{}/{}", self.did, self.collection, self.rkey)
    }
}
```

Add tests:

```rust
    #[test]
    fn test_aturi_parse() {
        let uri: AtUri = "at://did:plc:xyz/app.bsky.feed.post/3k2a1b".parse().unwrap();
        assert_eq!(uri.did.as_str(), "did:plc:xyz");
        assert_eq!(uri.collection.as_str(), "app.bsky.feed.post");
        assert_eq!(uri.rkey.as_str(), "3k2a1b");
    }

    #[test]
    fn test_aturi_roundtrip() {
        let original = "at://did:plc:z72i7hdynmk6r22z27h6tvur/app.bsky.feed.post/3l2s5xxv2ze2c";
        let uri: AtUri = original.parse().unwrap();
        assert_eq!(uri.to_string(), original);
    }

    #[test]
    fn test_aturi_storage_key() {
        let uri: AtUri = "at://did:plc:xyz/app.bsky.feed.post/abc".parse().unwrap();
        let key = uri.to_storage_key();
        assert_eq!(key, b"at://did:plc:xyz/app.bsky.feed.post/abc");
    }
```

**Step 8: Run all type tests**

Run: `cargo test`
Expected: All tests pass

**Step 9: Wire up module in main.rs**

Update `src/main.rs`:

```rust
mod types;

fn main() {
    println!(r#"
   ___  ______ ___  ___  ___
  / _ |/_  __// _ \/ _ \/ _ )
 / __ | / /  / ___/ // / _  |
/_/ |_|/_/  /_/  /____/____/
"#);
    println!("atp> (not yet implemented)");
}
```

**Step 10: Verify it still compiles**

Run: `cargo build`
Expected: Compiles without errors

**Step 11: Commit**

```bash
git add src/types.rs src/main.rs
git commit -m "feat: add native types (Did, Nsid, Rkey, AtUri)"
```

---

## Task 3: Storage Layer

**Files:**
- Create: `src/storage.rs`
- Modify: `src/main.rs`

**Step 1: Create storage module with Record struct**

Create `src/storage.rs`:

```rust
use crate::types::{AtUri, Did, Nsid};
use fjall::{Config, Keyspace, PartitionCreateOptions, PartitionHandle};
use serde::{Deserialize, Serialize};
use std::path::Path;
use thiserror::Error;

#[derive(Error, Debug)]
pub enum StorageError {
    #[error("fjall error: {0}")]
    Fjall(#[from] fjall::Error),
    #[error("serialization error: {0}")]
    Serialization(#[from] serde_json::Error),
    #[error("record not found")]
    NotFound,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Record {
    pub uri: String,
    pub cid: String,
    pub value: serde_json::Value,
    pub indexed_at: u64,
}

pub struct Store {
    #[allow(dead_code)]
    keyspace: Keyspace,
    records: PartitionHandle,
}

impl Store {
    pub fn open(path: &Path) -> Result<Self, StorageError> {
        let keyspace = Config::new(path).open()?;
        let records = keyspace.open_partition("records", PartitionCreateOptions::default())?;
        Ok(Store { keyspace, records })
    }

    pub fn put(&self, uri: &AtUri, record: &Record) -> Result<(), StorageError> {
        let key = uri.to_storage_key();
        let value = serde_json::to_vec(record)?;
        self.records.insert(key, value)?;
        Ok(())
    }

    pub fn get(&self, uri: &AtUri) -> Result<Option<Record>, StorageError> {
        let key = uri.to_storage_key();
        match self.records.get(&key)? {
            Some(bytes) => {
                let record: Record = serde_json::from_slice(&bytes)?;
                Ok(Some(record))
            }
            None => Ok(None),
        }
    }

    pub fn delete(&self, uri: &AtUri) -> Result<(), StorageError> {
        let key = uri.to_storage_key();
        self.records.remove(key)?;
        Ok(())
    }

    pub fn scan_collection(&self, did: &Did, collection: &Nsid) -> Result<Vec<Record>, StorageError> {
        let prefix = format!("at://{}/{}/", did, collection);
        let mut results = Vec::new();

        for item in self.records.prefix(prefix.as_bytes()) {
            let (_, value) = item?;
            let record: Record = serde_json::from_slice(&value)?;
            results.push(record);
        }

        Ok(results)
    }

    pub fn count(&self) -> Result<usize, StorageError> {
        Ok(self.records.len()?)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_store_put_get() {
        let dir = tempdir().unwrap();
        let store = Store::open(dir.path()).unwrap();

        let uri: AtUri = "at://did:plc:xyz/app.bsky.feed.post/abc".parse().unwrap();
        let record = Record {
            uri: uri.to_string(),
            cid: "bafytest".to_string(),
            value: serde_json::json!({"text": "hello"}),
            indexed_at: 1234567890,
        };

        store.put(&uri, &record).unwrap();
        let retrieved = store.get(&uri).unwrap().unwrap();

        assert_eq!(retrieved.cid, "bafytest");
        assert_eq!(retrieved.value["text"], "hello");
    }

    #[test]
    fn test_store_delete() {
        let dir = tempdir().unwrap();
        let store = Store::open(dir.path()).unwrap();

        let uri: AtUri = "at://did:plc:xyz/app.bsky.feed.post/abc".parse().unwrap();
        let record = Record {
            uri: uri.to_string(),
            cid: "bafytest".to_string(),
            value: serde_json::json!({}),
            indexed_at: 0,
        };

        store.put(&uri, &record).unwrap();
        store.delete(&uri).unwrap();
        assert!(store.get(&uri).unwrap().is_none());
    }

    #[test]
    fn test_store_scan_collection() {
        let dir = tempdir().unwrap();
        let store = Store::open(dir.path()).unwrap();

        let did: Did = "did:plc:xyz".parse().unwrap();
        let collection: Nsid = "app.bsky.feed.post".parse().unwrap();

        // Insert 3 posts
        for rkey in ["a", "b", "c"] {
            let uri: AtUri = format!("at://did:plc:xyz/app.bsky.feed.post/{}", rkey).parse().unwrap();
            let record = Record {
                uri: uri.to_string(),
                cid: format!("cid-{}", rkey),
                value: serde_json::json!({"rkey": rkey}),
                indexed_at: 0,
            };
            store.put(&uri, &record).unwrap();
        }

        // Insert 1 like (different collection)
        let like_uri: AtUri = "at://did:plc:xyz/app.bsky.feed.like/d".parse().unwrap();
        let like_record = Record {
            uri: like_uri.to_string(),
            cid: "cid-like".to_string(),
            value: serde_json::json!({}),
            indexed_at: 0,
        };
        store.put(&like_uri, &like_record).unwrap();

        let posts = store.scan_collection(&did, &collection).unwrap();
        assert_eq!(posts.len(), 3);
    }
}
```

**Step 2: Add tempfile dev dependency**

Update `Cargo.toml`:

```toml
[dev-dependencies]
tempfile = "3"
```

**Step 3: Run tests**

Run: `cargo test storage`
Expected: 3 tests pass

**Step 4: Wire up module in main.rs**

Update `src/main.rs`:

```rust
mod storage;
mod types;

fn main() {
    println!(r#"
   ___  ______ ___  ___  ___
  / _ |/_  __// _ \/ _ \/ _ )
 / __ | / /  / ___/ // / _  |
/_/ |_|/_/  /_/  /____/____/
"#);
    println!("atp> (not yet implemented)");
}
```

**Step 5: Verify build**

Run: `cargo build`
Expected: Compiles

**Step 6: Commit**

```bash
git add Cargo.toml src/storage.rs src/main.rs
git commit -m "feat: add storage layer with fjall"
```

---

## Task 4: Query Parser & Executor

**Files:**
- Create: `src/query.rs`
- Modify: `src/main.rs`

**Step 1: Create query module with types**

Create `src/query.rs`:

```rust
use crate::storage::{Record, Store, StorageError};
use crate::types::{AtUri, Did, Nsid, ParseError};
use thiserror::Error;

#[derive(Error, Debug)]
pub enum QueryError {
    #[error("parse error: {0}")]
    Parse(#[from] ParseError),
    #[error("storage error: {0}")]
    Storage(#[from] StorageError),
    #[error("invalid query: {0}")]
    Invalid(String),
}

#[derive(Debug, PartialEq)]
pub enum Query {
    Exact(AtUri),
    Collection { did: Did, collection: Nsid },
}

impl Query {
    pub fn parse(input: &str) -> Result<Self, QueryError> {
        let input = input.trim();

        if !input.starts_with("at://") {
            return Err(QueryError::Invalid("must start with at://".to_string()));
        }

        let without_scheme = &input[5..]; // Remove "at://"
        let parts: Vec<&str> = without_scheme.splitn(3, '/').collect();

        if parts.len() != 3 {
            return Err(QueryError::Invalid("expected did/collection/rkey".to_string()));
        }

        let did: Did = parts[0].parse()?;
        let collection: Nsid = parts[1].parse()?;
        let rkey = parts[2];

        if rkey == "*" {
            Ok(Query::Collection { did, collection })
        } else {
            let uri: AtUri = input.parse()?;
            Ok(Query::Exact(uri))
        }
    }
}

pub fn execute(query: &Query, store: &Store) -> Result<Vec<Record>, QueryError> {
    match query {
        Query::Exact(uri) => {
            match store.get(uri)? {
                Some(record) => Ok(vec![record]),
                None => Ok(vec![]),
            }
        }
        Query::Collection { did, collection } => {
            Ok(store.scan_collection(did, collection)?)
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_exact() {
        let q = Query::parse("at://did:plc:xyz/app.bsky.feed.post/abc").unwrap();
        match q {
            Query::Exact(uri) => {
                assert_eq!(uri.rkey.as_str(), "abc");
            }
            _ => panic!("expected Exact"),
        }
    }

    #[test]
    fn test_parse_collection() {
        let q = Query::parse("at://did:plc:xyz/app.bsky.feed.post/*").unwrap();
        match q {
            Query::Collection { did, collection } => {
                assert_eq!(did.as_str(), "did:plc:xyz");
                assert_eq!(collection.as_str(), "app.bsky.feed.post");
            }
            _ => panic!("expected Collection"),
        }
    }

    #[test]
    fn test_parse_invalid() {
        assert!(Query::parse("not-a-uri").is_err());
        assert!(Query::parse("at://did:plc:xyz").is_err());
    }
}
```

**Step 2: Run tests**

Run: `cargo test query`
Expected: 3 tests pass

**Step 3: Wire up module**

Update `src/main.rs`:

```rust
mod query;
mod storage;
mod types;

fn main() {
    println!(r#"
   ___  ______ ___  ___  ___
  / _ |/_  __// _ \/ _ \/ _ )
 / __ | / /  / ___/ // / _  |
/_/ |_|/_/  /_/  /____/____/
"#);
    println!("atp> (not yet implemented)");
}
```

**Step 4: Verify build**

Run: `cargo build`
Expected: Compiles

**Step 5: Commit**

```bash
git add src/query.rs src/main.rs
git commit -m "feat: add query parser and executor"
```

---

## Task 5: Indexer (Ref Extraction)

**Files:**
- Create: `src/indexer.rs`
- Modify: `src/main.rs`

**Step 1: Create indexer with ref extraction**

Create `src/indexer.rs`:

```rust
use crate::types::AtUri;
use serde_json::Value;

pub fn extract_refs(value: &Value) -> Vec<AtUri> {
    let mut refs = Vec::new();
    walk_json(value, &mut refs);
    refs
}

fn walk_json(value: &Value, refs: &mut Vec<AtUri>) {
    match value {
        Value::String(s) if s.starts_with("at://") => {
            if let Ok(uri) = s.parse::<AtUri>() {
                refs.push(uri);
            }
        }
        Value::Object(map) => {
            for v in map.values() {
                walk_json(v, refs);
            }
        }
        Value::Array(arr) => {
            for v in arr {
                walk_json(v, refs);
            }
        }
        _ => {}
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;

    #[test]
    fn test_extract_no_refs() {
        let value = json!({"text": "hello world"});
        let refs = extract_refs(&value);
        assert!(refs.is_empty());
    }

    #[test]
    fn test_extract_single_ref() {
        let value = json!({
            "subject": {
                "uri": "at://did:plc:xyz/app.bsky.feed.post/abc"
            }
        });
        let refs = extract_refs(&value);
        assert_eq!(refs.len(), 1);
        assert_eq!(refs[0].to_string(), "at://did:plc:xyz/app.bsky.feed.post/abc");
    }

    #[test]
    fn test_extract_multiple_refs() {
        let value = json!({
            "reply": {
                "root": {"uri": "at://did:plc:a/app.bsky.feed.post/1"},
                "parent": {"uri": "at://did:plc:b/app.bsky.feed.post/2"}
            }
        });
        let refs = extract_refs(&value);
        assert_eq!(refs.len(), 2);
    }

    #[test]
    fn test_extract_refs_in_array() {
        let value = json!({
            "items": [
                {"uri": "at://did:plc:a/app.bsky.feed.post/1"},
                {"uri": "at://did:plc:b/app.bsky.feed.post/2"}
            ]
        });
        let refs = extract_refs(&value);
        assert_eq!(refs.len(), 2);
    }

    #[test]
    fn test_ignore_invalid_at_uri() {
        let value = json!({"text": "at://not-valid"});
        let refs = extract_refs(&value);
        assert!(refs.is_empty());
    }
}
```

**Step 2: Run tests**

Run: `cargo test indexer`
Expected: 5 tests pass

**Step 3: Wire up module**

Update `src/main.rs`:

```rust
mod indexer;
mod query;
mod storage;
mod types;

fn main() {
    println!(r#"
   ___  ______ ___  ___  ___
  / _ |/_  __// _ \/ _ \/ _ )
 / __ | / /  / ___/ // / _  |
/_/ |_|/_/  /_/  /____/____/
"#);
    println!("atp> (not yet implemented)");
}
```

**Step 4: Verify build**

Run: `cargo build`
Expected: Compiles

**Step 5: Commit**

```bash
git add src/indexer.rs src/main.rs
git commit -m "feat: add indexer with ref extraction"
```

---

## Task 6: Firehose Client

**Files:**
- Create: `src/firehose.rs`
- Modify: `src/main.rs`
- Modify: `Cargo.toml`

**Step 1: Add additional dependencies**

Update `Cargo.toml` dependencies:

```toml
[dependencies]
fjall = "2"
tungstenite = "0.24"
ciborium = "0.2"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
serde_bytes = "0.11"
serde_ipld_dagcbor = "0.6"
rustyline = "14"
thiserror = "2"
url = "2"
libipld = { version = "0.16", features = ["dag-cbor"] }
```

**Step 2: Create firehose client skeleton**

Create `src/firehose.rs`:

```rust
use crate::types::{AtUri, Did};
use serde::Deserialize;
use std::io::Cursor;
use thiserror::Error;
use tungstenite::{connect, Message};

#[derive(Error, Debug)]
pub enum FirehoseError {
    #[error("websocket error: {0}")]
    WebSocket(#[from] tungstenite::Error),
    #[error("cbor decode error: {0}")]
    Cbor(String),
    #[error("invalid message")]
    InvalidMessage,
}

#[derive(Debug)]
pub enum Event {
    Commit {
        did: Did,
        operations: Vec<Operation>,
    },
    Unknown,
}

#[derive(Debug)]
pub enum Operation {
    Create {
        uri: AtUri,
        cid: String,
        value: serde_json::Value,
    },
    Delete {
        uri: AtUri,
    },
}

#[derive(Debug, Deserialize)]
struct Header {
    op: i32,
    t: Option<String>,
}

#[derive(Debug, Deserialize)]
struct CommitBody {
    repo: String,
    ops: Vec<RepoOp>,
    #[serde(with = "serde_bytes")]
    blocks: Vec<u8>,
}

#[derive(Debug, Deserialize)]
struct RepoOp {
    action: String,
    path: String,
    cid: Option<libipld::Cid>,
}

pub struct FirehoseClient {
    socket: tungstenite::WebSocket<tungstenite::stream::MaybeTlsStream<std::net::TcpStream>>,
}

impl FirehoseClient {
    pub fn connect(relay: &str) -> Result<Self, FirehoseError> {
        let url = format!("wss://{}/xrpc/com.atproto.sync.subscribeRepos", relay);
        let (socket, _response) = connect(&url)?;
        Ok(FirehoseClient { socket })
    }

    pub fn next_event(&mut self) -> Result<Option<Event>, FirehoseError> {
        loop {
            let msg = self.socket.read()?;

            match msg {
                Message::Binary(data) => {
                    return self.decode_message(&data);
                }
                Message::Close(_) => return Ok(None),
                _ => continue,
            }
        }
    }

    fn decode_message(&self, data: &[u8]) -> Result<Option<Event>, FirehoseError> {
        let mut cursor = Cursor::new(data);

        // Decode header
        let header: Header = ciborium::from_reader(&mut cursor)
            .map_err(|e| FirehoseError::Cbor(e.to_string()))?;

        // Only handle commits (op=1, t="#commit")
        if header.op != 1 || header.t.as_deref() != Some("#commit") {
            return Ok(Some(Event::Unknown));
        }

        // Decode commit body
        let body: CommitBody = ciborium::from_reader(&mut cursor)
            .map_err(|e| FirehoseError::Cbor(e.to_string()))?;

        let did: Did = body.repo.parse()
            .map_err(|_| FirehoseError::InvalidMessage)?;

        // Parse CAR blocks to get record data
        let blocks = self.parse_car_blocks(&body.blocks)?;

        let mut operations = Vec::new();
        for op in body.ops {
            match op.action.as_str() {
                "create" | "update" => {
                    if let Some(cid) = &op.cid {
                        if let Some(value) = blocks.get(&cid.to_string()) {
                            let parts: Vec<&str> = op.path.splitn(2, '/').collect();
                            if parts.len() == 2 {
                                let uri_str = format!("at://{}/{}", did, op.path);
                                if let Ok(uri) = uri_str.parse() {
                                    operations.push(Operation::Create {
                                        uri,
                                        cid: cid.to_string(),
                                        value: value.clone(),
                                    });
                                }
                            }
                        }
                    }
                }
                "delete" => {
                    let uri_str = format!("at://{}/{}", did, op.path);
                    if let Ok(uri) = uri_str.parse() {
                        operations.push(Operation::Delete { uri });
                    }
                }
                _ => {}
            }
        }

        Ok(Some(Event::Commit { did, operations }))
    }

    fn parse_car_blocks(&self, car_bytes: &[u8]) -> Result<std::collections::HashMap<String, serde_json::Value>, FirehoseError> {
        let mut blocks = std::collections::HashMap::new();

        if car_bytes.is_empty() {
            return Ok(blocks);
        }

        let mut cursor = Cursor::new(car_bytes);

        // Read CAR header (varint length + dag-cbor header)
        let header_len = read_varint(&mut cursor)
            .map_err(|e| FirehoseError::Cbor(e.to_string()))?;

        // Skip header bytes
        let pos = cursor.position() as usize;
        if pos + header_len > car_bytes.len() {
            return Ok(blocks);
        }
        cursor.set_position((pos + header_len) as u64);

        // Read blocks
        while (cursor.position() as usize) < car_bytes.len() {
            let block_start = cursor.position() as usize;

            let block_len = match read_varint(&mut cursor) {
                Ok(len) => len,
                Err(_) => break,
            };

            let cid_start = cursor.position() as usize;
            if cid_start + block_len > car_bytes.len() {
                break;
            }

            // Parse CID
            let cid = match parse_cid(&car_bytes[cid_start..]) {
                Ok((cid, cid_len)) => {
                    cursor.set_position((cid_start + cid_len) as u64);
                    cid
                }
                Err(_) => break,
            };

            // Read block data
            let data_start = cursor.position() as usize;
            let data_end = block_start + block_len + varint_len(block_len);

            if data_end > car_bytes.len() {
                break;
            }

            let block_data = &car_bytes[data_start..data_end];
            cursor.set_position(data_end as u64);

            // Try to decode as dag-cbor and convert to JSON
            if let Ok(value) = serde_ipld_dagcbor::from_slice::<serde_json::Value>(block_data) {
                blocks.insert(cid, value);
            }
        }

        Ok(blocks)
    }
}

fn read_varint<R: std::io::Read>(reader: &mut R) -> Result<usize, std::io::Error> {
    let mut result: usize = 0;
    let mut shift = 0;

    loop {
        let mut byte = [0u8; 1];
        reader.read_exact(&mut byte)?;

        result |= ((byte[0] & 0x7f) as usize) << shift;
        if byte[0] & 0x80 == 0 {
            break;
        }
        shift += 7;

        if shift > 63 {
            return Err(std::io::Error::new(std::io::ErrorKind::InvalidData, "varint too long"));
        }
    }

    Ok(result)
}

fn varint_len(n: usize) -> usize {
    let mut len = 1;
    let mut n = n;
    while n >= 0x80 {
        len += 1;
        n >>= 7;
    }
    len
}

fn parse_cid(data: &[u8]) -> Result<(String, usize), &'static str> {
    if data.is_empty() {
        return Err("empty cid");
    }

    // CIDv1: version (1) + codec + multihash
    if data[0] == 0x01 {
        // Read codec varint
        let mut pos = 1;
        while pos < data.len() && data[pos] & 0x80 != 0 {
            pos += 1;
        }
        pos += 1; // Include last byte of codec

        if pos >= data.len() {
            return Err("truncated cid");
        }

        // Read multihash: hash_type + hash_len + hash_bytes
        let hash_type_start = pos;
        while pos < data.len() && data[pos] & 0x80 != 0 {
            pos += 1;
        }
        pos += 1; // hash type

        if pos >= data.len() {
            return Err("truncated cid");
        }

        let hash_len = data[pos] as usize;
        pos += 1;
        pos += hash_len;

        let cid_bytes = &data[..pos];
        let cid = libipld::Cid::try_from(cid_bytes)
            .map_err(|_| "invalid cid")?;

        Ok((cid.to_string(), pos))
    } else {
        Err("unsupported cid version")
    }
}
```

**Step 3: Wire up module**

Update `src/main.rs`:

```rust
mod firehose;
mod indexer;
mod query;
mod storage;
mod types;

fn main() {
    println!(r#"
   ___  ______ ___  ___  ___
  / _ |/_  __// _ \/ _ \/ _ )
 / __ | / /  / ___/ // / _  |
/_/ |_|/_/  /_/  /____/____/
"#);
    println!("atp> (not yet implemented)");
}
```

**Step 4: Verify build**

Run: `cargo build`
Expected: Compiles (may have warnings about unused code)

**Step 5: Commit**

```bash
git add Cargo.toml src/firehose.rs src/main.rs
git commit -m "feat: add firehose client with CBOR/CAR decoding"
```

---

## Task 7: CLI REPL

**Files:**
- Modify: `src/main.rs`

**Step 1: Implement full REPL**

Replace `src/main.rs`:

```rust
mod firehose;
mod indexer;
mod query;
mod storage;
mod types;

use firehose::{Event, FirehoseClient, Operation};
use query::Query;
use rustyline::error::ReadlineError;
use rustyline::DefaultEditor;
use std::path::Path;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::thread;
use std::time::{SystemTime, UNIX_EPOCH};

fn main() {
    println!(r#"
   ___  ______ ___  ___  ___
  / _ |/_  __// _ \/ _ \/ _ )
 / __ | / /  / ___/ // / _  |
/_/ |_|/_/  /_/  /____/____/
"#);

    let store = match storage::Store::open(Path::new("./atpdb.data")) {
        Ok(s) => Arc::new(s),
        Err(e) => {
            eprintln!("Failed to open storage: {}", e);
            return;
        }
    };

    let running = Arc::new(AtomicBool::new(false));
    let mut rl = DefaultEditor::new().unwrap();

    loop {
        let prompt = if running.load(Ordering::Relaxed) {
            "atp> (streaming) "
        } else {
            "atp> "
        };

        match rl.readline(prompt) {
            Ok(line) => {
                let line = line.trim();
                if line.is_empty() {
                    continue;
                }

                let _ = rl.add_history_entry(line);

                match line {
                    ".quit" | ".exit" => break,

                    ".help" => {
                        println!("Commands:");
                        println!("  .connect <relay>  Connect to firehose (default: bsky.network)");
                        println!("  .disconnect       Stop firehose");
                        println!("  .stats            Show statistics");
                        println!("  .quit             Exit");
                        println!();
                        println!("Queries:");
                        println!("  at://did/collection/rkey   Get single record");
                        println!("  at://did/collection/*      Get all records in collection");
                    }

                    ".stats" => {
                        match store.count() {
                            Ok(count) => println!("Records: {}", count),
                            Err(e) => println!("Error: {}", e),
                        }
                    }

                    ".disconnect" => {
                        running.store(false, Ordering::Relaxed);
                        println!("Disconnecting...");
                    }

                    cmd if cmd.starts_with(".connect") => {
                        let relay = cmd
                            .strip_prefix(".connect")
                            .map(|s| s.trim())
                            .filter(|s| !s.is_empty())
                            .unwrap_or("bsky.network");

                        if running.load(Ordering::Relaxed) {
                            println!("Already connected. Use .disconnect first.");
                            continue;
                        }

                        let store_clone = Arc::clone(&store);
                        let running_clone = Arc::clone(&running);
                        let relay = relay.to_string();

                        running.store(true, Ordering::Relaxed);

                        thread::spawn(move || {
                            match FirehoseClient::connect(&relay) {
                                Ok(mut client) => {
                                    println!("Connected to {}", relay);

                                    while running_clone.load(Ordering::Relaxed) {
                                        match client.next_event() {
                                            Ok(Some(Event::Commit { did: _, operations })) => {
                                                for op in operations {
                                                    match op {
                                                        Operation::Create { uri, cid, value } => {
                                                            let record = storage::Record {
                                                                uri: uri.to_string(),
                                                                cid,
                                                                value,
                                                                indexed_at: SystemTime::now()
                                                                    .duration_since(UNIX_EPOCH)
                                                                    .unwrap()
                                                                    .as_secs(),
                                                            };
                                                            if let Err(e) = store_clone.put(&uri, &record) {
                                                                eprintln!("Storage error: {}", e);
                                                            }
                                                        }
                                                        Operation::Delete { uri } => {
                                                            if let Err(e) = store_clone.delete(&uri) {
                                                                eprintln!("Storage error: {}", e);
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                            Ok(Some(Event::Unknown)) => {}
                                            Ok(None) => {
                                                println!("Connection closed");
                                                break;
                                            }
                                            Err(e) => {
                                                eprintln!("Firehose error: {}", e);
                                                break;
                                            }
                                        }
                                    }
                                }
                                Err(e) => {
                                    eprintln!("Failed to connect: {}", e);
                                }
                            }
                            running_clone.store(false, Ordering::Relaxed);
                        });
                    }

                    line if line.starts_with("at://") => {
                        match Query::parse(line) {
                            Ok(q) => {
                                let start = std::time::Instant::now();
                                match query::execute(&q, &store) {
                                    Ok(records) => {
                                        let elapsed = start.elapsed();
                                        for record in &records {
                                            println!("{}", serde_json::to_string_pretty(&record.value).unwrap());
                                            println!("---");
                                        }
                                        println!("({} records, {:.2?})", records.len(), elapsed);
                                    }
                                    Err(e) => println!("Query error: {}", e),
                                }
                            }
                            Err(e) => println!("Parse error: {}", e),
                        }
                    }

                    _ => println!("Unknown command. Type .help for help."),
                }
            }
            Err(ReadlineError::Interrupted) => {
                println!("^C");
            }
            Err(ReadlineError::Eof) => {
                break;
            }
            Err(e) => {
                println!("Error: {:?}", e);
                break;
            }
        }
    }

    running.store(false, Ordering::Relaxed);
    println!("Goodbye!");
}
```

**Step 2: Verify build**

Run: `cargo build`
Expected: Compiles

**Step 3: Test manually**

Run: `cargo run`
Expected: Banner prints, REPL starts, can type `.help`, `.stats`, `.quit`

**Step 4: Commit**

```bash
git add src/main.rs
git commit -m "feat: add CLI REPL with firehose integration"
```

---

## Task 8: Integration Test

**Files:**
- Create: `tests/integration.rs`

**Step 1: Create integration test**

Create `tests/integration.rs`:

```rust
use std::process::Command;

#[test]
fn test_binary_runs() {
    let output = Command::new("cargo")
        .args(["run", "--", "--help"])
        .output()
        .expect("failed to run");

    // Just verify it doesn't crash on startup
    // (it will exit with unknown flag, but that's fine)
    assert!(output.status.code().is_some());
}
```

**Step 2: Run test**

Run: `cargo test --test integration`
Expected: Test passes

**Step 3: Commit**

```bash
git add tests/integration.rs
git commit -m "test: add integration test"
```

---

## Task 9: Final Cleanup

**Step 1: Run clippy**

Run: `cargo clippy -- -D warnings`
Fix any warnings.

**Step 2: Format code**

Run: `cargo fmt`

**Step 3: Run all tests**

Run: `cargo test`
Expected: All tests pass

**Step 4: Final commit**

```bash
git add -A
git commit -m "chore: clippy fixes and formatting"
```

---

## Done!

After completing all tasks, you'll have a working atpdb MVP:

```bash
$ cargo run

   ___  ______ ___  ___  ___
  / _ |/_  __// _ \/ _ \/ _ )
 / __ | / /  / ___/ // / _  |
/_/ |_|/_/  /_/  /____/____/

atp> .connect
Connected to bsky.network
atp> .stats
Records: 1234
atp> at://did:plc:xyz/app.bsky.feed.post/*
[records...]
atp> .quit
Goodbye!
```
